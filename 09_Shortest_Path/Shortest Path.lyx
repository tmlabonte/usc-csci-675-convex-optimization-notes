#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\begin_modules
theorems-ams
algolyx
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date true
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Shortest Path
\end_layout

\begin_layout Section
Discrete Problems as Linear Programs
\end_layout

\begin_layout Standard
In computer science, discrete problems are often solved with discrete algorithms
; in optimization, discrete problems are often solved with continuous optimizati
on.
 Modern theory accepts that both methods are useful and each can provide
 insights into the problem.
\end_layout

\begin_layout Standard
To cast a discrete problem as an LP, note that any finite family of discrete
 objects is equivalent to a finite Euclidean subspace.
 The convex hull of this subspace is a polytope, which we know how to optimize
 over.
 Furthermore, LPs require a 
\begin_inset Quotes eld
\end_inset

small
\begin_inset Quotes erd
\end_inset

 family of inequalities, which is impossible when a problem is 
\series bold
NP
\series default
-hard.
\end_layout

\begin_layout Section
Shortest Path LP
\end_layout

\begin_layout Subsection
Shortest Path Problem
\end_layout

\begin_layout Problem*
Given a directed graph 
\begin_inset Formula $G=(V,E)$
\end_inset

 with cost 
\begin_inset Formula $c_{e}\in\mathbb{R}$
\end_inset

 on each edge 
\begin_inset Formula $e\in E$
\end_inset

, find the minimum cost path from 
\begin_inset Formula $s\rightarrow t$
\end_inset

 with 
\begin_inset Formula $s,t\in V$
\end_inset

, assuming there is one.
 Let 
\begin_inset Formula $n=|V|$
\end_inset

 and 
\begin_inset Formula $m=|E|$
\end_inset

 and allow negative costs but not negative cycles.
 When the costs are positive, Dijkstra's Algorithm solves this problem in
 
\begin_inset Formula $\mathcal{O}(m+n\log n)$
\end_inset

.
\end_layout

\begin_layout Standard
Note that no negative cycles implies that a simple path exists; if negative
 cycles exist but we want the shortest path which does not encounter the
 negative cycle, this problem is 
\series bold
NP
\series default
-hard by reduction from Hamiltonian Cycle.
 Usually, we will implement our algorithm to fail gracefully when it encounters
 a negative cycle.
\end_layout

\begin_layout Subsection
Integrality of the Shortest Path
\end_layout

\begin_layout Standard
In order to encode this problem as an LP, we have to relax the problem and
 allow fractional paths.
 Let 
\begin_inset Formula $\delta_{v}=-1$
\end_inset

 if 
\begin_inset Formula $v=s$
\end_inset

, 
\begin_inset Formula $\delta_{v}=1$
\end_inset

 if 
\begin_inset Formula $v=t$
\end_inset

, and 
\begin_inset Formula $\delta_{v}=0$
\end_inset

 otherwise.
 Then we have the LP:
\begin_inset Formula 
\begin{align*}
\min\text{ } & \sum_{e\in E}c_{e}x_{e}\\
\text{s.t. } & \sum_{e\rightarrow v}x_{e}-\sum_{v\rightarrow e}x_{e}=\delta_{v}\text{ }\forall v\\
 & \boldsymbol{x}\succeq0
\end{align*}

\end_inset

The primal LP encodes the idea that the path should leave 
\begin_inset Formula $s$
\end_inset

 once, enter and leave every other node in the path once, and enter 
\begin_inset Formula $t$
\end_inset

 once, with minimal cost.
 We will show that the shortest integral path from 
\begin_inset Formula $s\rightarrow t$
\end_inset

, denoted 
\begin_inset Formula $\boldsymbol{x}^{*}$
\end_inset

, is a solution to the primal LP by taking the dual:
\begin_inset Formula 
\begin{align*}
\max\text{ } & y_{t}-y_{s}\\
\text{s.t. } & y_{v}-y_{u}\leq c_{e}\text{ }\forall(u,v)\in E
\end{align*}

\end_inset

The dual LP encodes the idea that we want to find the maximum distance we
 can 
\begin_inset Quotes eld
\end_inset

stretch
\begin_inset Quotes erd
\end_inset

 the graph at 
\begin_inset Formula $s$
\end_inset

 and 
\begin_inset Formula $t$
\end_inset

 without 
\begin_inset Quotes eld
\end_inset

over-stretching
\begin_inset Quotes erd
\end_inset

 the edge between any two nodes.
 Let 
\begin_inset Formula $y_{v}^{*}$
\end_inset

 be the shortest path distance from 
\begin_inset Formula $s\rightarrow v$
\end_inset

.
 Then:
\begin_inset Formula 
\[
\sum_{e\in E}c_{e}x_{e}^{*}=y_{t}^{*}-y_{s}^{*}
\]

\end_inset

So by strong duality, both 
\begin_inset Formula $\boldsymbol{x}^{*}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{y}^{*}$
\end_inset

 are optimal.
\end_layout

\begin_layout Subsection
Integrality of Polyhedra
\end_layout

\begin_layout Standard
The above observation leads us to a stronger statement whose generalization
 is useful in many combinatorial contexts; that is, that the vertices of
 the polyhedral feasible region of a relaxed combinatorial LP are precisely
 the indicator vectors of the optimal solutions.
 Here, we show that the vertices are the indicator vectors of the shortest
 paths.
\end_layout

\begin_layout Proof
First, we know our LP is bounded if and only if we disallow negative cycles
 in the objective function 
\begin_inset Formula $c$
\end_inset

.
 Furthermore, for every vertex 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

 (representing an integral path), there is an objective function 
\begin_inset Formula $c$
\end_inset

 such that 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

 is the unique optimal.
 Since such a 
\begin_inset Formula $c$
\end_inset

 disallows negative cycles, we must have that 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

 is integral.
\end_layout

\begin_layout Standard
We can use this same proof strategy in the general case.
 To show that a polytope's vertices are integral, it suffices to show that
 there is an integral optimal for any objective which admits an optimal
 solution.
\end_layout

\begin_layout Section
Primal-Dual Algorithms
\end_layout

\begin_layout Standard
For convenience, we can add an edge of infinite length from 
\begin_inset Formula $s\rightarrow v$
\end_inset

 when one does not exist.
 Then, we can study a 
\series bold
primal-dual algorithm
\series default
 for finding the shortest path, which simultaneously builds optimal solutions
 for the primal and dual LPs.
 The algorithm then terminates when they are equal, since by duality we
 will have reached an optimal solution.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Algorithm
* 
\begin_inset Formula $y_{v}=c_{(s,v)},pred(v)=s\text{ }\forall v\neq s$
\end_inset


\end_layout

\begin_layout Algorithm
* 
\begin_inset Formula $y_{s}=0,pred(s)=null$
\end_inset


\end_layout

\begin_layout Algorithm
while 
\begin_inset Formula $y_{v}>y_{u}+c_{e}$
\end_inset

 for some 
\begin_inset Formula $e=(u,v)\in E$
\end_inset


\end_layout

\begin_deeper
\begin_layout Algorithm
* 
\begin_inset Formula $pred(v)=u$
\end_inset


\end_layout

\begin_layout Algorithm
* 
\begin_inset Formula $y_{v}=y_{u}+c_{e}$
\end_inset


\end_layout

\end_deeper
\begin_layout Algorithm
endwhile
\end_layout

\begin_layout Algorithm
return 
\begin_inset Formula $t,pred(t),pred(pred(t)),\dots$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Ford's Algorithm
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Ford's Algorithm maintains an initially infeasible dual 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 and builds a candidate feasible primal 
\begin_inset Formula $\boldsymbol{p}$
\end_inset

 of length 
\begin_inset Formula $\leq y_{t}-y_{s}$
\end_inset

.
 Then, it iteratively fixes 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 towards feasibility; once 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 is feasible, weak duality implies that we have an optimal solution.
 Note that Ford's Algorithm actually solves the single-source shortest path
 problem, because it found the shortest paths from 
\begin_inset Formula $s$
\end_inset

 to every other node, not just 
\begin_inset Formula $t$
\end_inset

.
 The proof of runtime of Ford's Algorithm is slightly technical, but by
 fixing an arbitrary order on the edges while looking for a violation of
 a dual constraint, we derive the Bellman-Ford Algorithm, which runs in
 
\begin_inset Formula $\mathcal{O}(mn)$
\end_inset

 time
\end_layout

\end_body
\end_document
